(ns sicp-clojure.c1-2
  (:require [sicp-clojure.c1-1 :as c1-1]))

;;;; 1.2 Procedures and the Processes They Generate

;; A procedure is a pattern for the "local evolution" of a computational
;; process. It specifies how each stage of the process is build upon the
;; previous stage. In this section, we look at some common "shapes" for the
;; processes generated by simple procedures.

;;; 1.2.1 Linear Recursion and Iteration

;; We begin by considering the factorial function using a linear recursive process:

(defn fact1
  "Return Factorial using recursive process"
  [n]
  (if (= n 1)
    1
    (* n (fact1 (- n 1)))))

;; (factorial 6)        ------------------------.
;; (* 6 (factorial 5))                          |
;; (* 6 (* 5 (factorial 4)))                    |
;; (* 6 (* 5 (* 4 (factorial 3))))              |
;; (* 6 (* 5 (* 4 (* 3 (factorial 2)))))        |
;; (* 6 (* 5 (* 4 (* 3 (* 2 (factorial 1))))))  |
;; (* 6 (* 5 (* 4 (* 3 (* 2 1)))))              |
;; (* 6 (* 5 (* 4 (* 3 2))))                    |
;; (* 6 (* 5 (* 4 6)))                          |
;; (* 6 (* 5 24))                               |
;; (* 6 120)                                    |
;; 720          <-------------------------------'

;; Another approach could be building up a value, keeping a running sum.

(defn fact2
  "Return Factorial using iterative process"
  [n]
  (loop [acc 1
         i 1]
    (if (> i n)
      acc
      (recur (* i acc)
             (inc i)))))

;; (factorial 6)   -----.
;; (fact-iter   1 1 6)  |
;; (fact-iter   1 2 6)  |
;; (fact-iter   2 3 6)  |
;; (fact-iter   6 4 6)  |
;; (fact-iter  24 5 6)  |
;; (fact-iter 120 6 6)  |
;; (fact-iter 720 7 6)  V
;; 720

;; The two functions evaluate to the same result, but using very different
;; shapes. The recursive process builds up a chain of deferred computations. In
;; order to know the state, you need to understand the state of the stack. In
;; contrast, with an iterative shape, the accumulated state of the computation
;; is state (or a parameter) of the function.

;; Exercise 1.9: Each of the following two procedures defines a method for
;; adding two positive integres in terms of the procedures `inc', which
;; increments its argument by 1, and `dec', which decrements its argument by 1.
(defn my-plus1
  ""
  [a b]
  (if (= a 0)
    b
    (inc (my-plus1 (dec a) b))))

(defn my-plus2
  ""
  [a b]
  (if (= a 0)
    b
    (my-plus2 (dec a) (inc b))))

;; These processes are recursive

;; Exercise 1.10: The following procedure computes a matehmatical function
;; called Ackermann's function.

(defn ackerman
  "Ackerman's function"
  [x y]
  (cond
    (= y 0) 0
    (= x 0) (* 2 y)
    (= y 1) 2
    :else (ackerman (- x 1) (ackerman x (- y 1)))))

;; What are the values of the following expressions?
;;
;; (ackerman 1 10) => 1024
;; (ackerman 2 4) => 65536
;; (ackerman 3 3) => 65536
;;
;; Consider the following procedures, where `A' is the procedure defined above:
;;
;; (defn f [n] (ackerman 0 n)) => computes 0
;; (defn g [n] (ackernam 1 n)) => computes 2^n
;; (defn h [n] (ackernam 2 n)) => computes (2^n)^2

;;; 1.2.2 Tree Recursion

;; Another common pattern of computation is "tree recursion", and Fibonacci
;; numbers are an example of this, in the sequence:

;; 0, 1, 1, 2, 3, 4, 8, 13, 21, ...

;;          | 0 if n = 0
;; fib(n) = | 1 if n = 1
;;          | fib(n-1) + fib(n-2)

;; Consider a recursive procedure implemmentation:

(defn fib1
  "Expensive computation of Fibonacci"
  [n]
  (cond
    (= n 0) 0
    (= n 1) 1
    :else (+ (fib1 (- n 1)) (fib1 (- n 2)))))

;; While this function is illustrative of tree recursion, it is a terrible way
;; to compute the Fibonacci sequence because there is so much redundant
;; computation. Consider:

;;                    ..<............ fib5   <..........
;;                 ...     ___________/  \___________   .
;;              ...       /       . .....            \    .
;;            ..       fib4     .        . . . .     fib3  .
;;          ..     ____/. \____  ..             .  __/  \__  .
;;        ..      /  . .  ..   \    .        ..   /  . .   \   .
;;      ..     fib3 .       .  fib2 .        . fib2 .   .  fib1 .
;;    ..      / . \  .     .   /  \  .      .  /  \ ...  .  |  .
;;  ..       / . . \   .  .   /  . \   .  .   / .  \   .  . 1 .
;; .      fib2 . . fib1.  .fib1 .  fib0 . .fib1. . fib0 .  .  .
;; .      /  \  . . |  .  . |  .  . |   . . |   . . |   .   .>
;; .     /  . \   . 1  .  . 1  .  . 0  .  . 1  .  . 0  ..
;; .  fib1 .. fib0..  .   .   .   .   .   V   .   ..  .
;; .   |  .  . |  . .>     .>.     . .    ..>.      .>
;; .   1 .   . 0  .
;;  .   .     .  .
;;   .>.       ..

;; This computation grows exponentially in terms, but minimizes memory usage. In
;; contrast, the iterative solution produces a result that is proportional to
;; the size of N, rather than exponential:

(defn fib2
  [n]
  (if (< n 1)
    0
    (loop [a 1
           b 1
           i 1]
      (if (= i n)
        a
        (recur b (+ a b) (inc i))))))

(def fib-memoized (memoize fib2))

;; This does not mean that tree recursion is never useful, it is a natural and
;; powerful tool.

;; In some cases, however, there is no alternative to tree recursion. Consider,
;; for example, counting change. How many different ways can we make change for
;; $1.00, given half-dollars, quarters, dimes, nickels, and pennies.

;; We can reason about the solution to the problem as two cases:
;;   a. number of ways to change `a' using all but the first kind of coin, plus
;;   b. number of ways to change amount `a - d' using all `n' kinds of coins,
;;      where d is the denomination of the first kind of coin

;; This is because the solution can be divided between those that use the first
;; kind of coin and those that do not. Thus, we can recursively reduce the
;; problem of changing a given amount to the problem of changing smaller amounts
;; using fewer kinds of coins.

;; Here is the algorithm:
;;   * if `a' is exactly 0, we should count that as 1 way to make change.
;;   * If `a' is less than 0, we should count that as 0 ways to make change.
;;   * If `n' is 0, we should count that as 0 ways to make change.

(defn first-denomination
  [kinds-of-coins]
  (cond (= kinds-of-coins 1) 1
        (= kinds-of-coins 2) 5
        (= kinds-of-coins 3) 10
        (= kinds-of-coins 4) 25
        (= kinds-of-coins 5) 50))

(defn cc
  [amount kinds-of-coins]
  (cond (= amount 0) 1
        (or (< amount 0) (= kinds-of-coins 0)) 0
        :else (+ (cc amount
                     (dec kinds-of-coins))
                 (cc (- amount (first-denomination kinds-of-coins))
                     kinds-of-coins))))

(defn count-change [amount]
  (cc amount 5))

;; The observation that a tree-recursive proces maybe highly inefficient but
;; often easy to specify and understand has let people to propose that one could
;; get the best of both worlds by designing a "smart compiler" that could
;; transform tree-recursive procedures into more efficient procedures that
;; compute the same result.

;; Exercise 1.11: A function `f' is defined by the rule that f(n) = n if n < 3
;; and f(n) = f(n-1) + 2f(n-2) + 3f(n-3) if n >= 3. Write a procedure that
;; computes `f' by means of a recursive process. Write a procedures that
;; computes `f' by means of an iterative process.

(defn f-recursive
  [n]
  (if (< n 3)
    n
    (+ (* 1 (f-recursive (- n 1)))
       (* 2 (f-recursive (- n 2)))
       (* 3 (f-recursive (- n 3))))))

(defn f-iterative
  [n]
  (if (< n 3)
    n
    (loop [acc '(2 1 0)
           i 2]
      (if (= i n)
        (first acc)
        (let [f1 (nth acc 0)
              f2 (nth acc 1)
              f3 (nth acc 2)
              next (+ (* 1 f1)
                      (* 2 f2)
                      (* 3 f3))]
          (recur (conj acc next)
                 (inc i)))))))

;; Exercise 1.12: The following pattern of numbers is called "Pascal's
;; triangle".

;;              1
;;            1   1
;;          1   2   1
;;        1   3   3   1
;;      1   4   6   4   1

;; The numbers at the edge of the triangle are all 1, and each number inside the
;; triangle is the sum of the two numbers above it. Write a procedure that
;; computes elements of Pascal's triangle by means of a recursive process

(defn- private-pascal-next
  "Return next row of Pascal's Triangle, given seq of current row"
  [row]
  (loop [acc (list 1)
         rem row]
    (let [[a b] rem]
      (if (nil? b)
        (conj acc 1)
        (recur (conj acc (+ a b)) (rest rem))))))

(defn pascal
  "Return Pascal's Triangle with `n' rows, as a list of lists'"
  [n]
  (cond (< n 1) ()
        (= n 1) (list (list 1))
        :else (let [[base :as triangle] (pascal (dec n))]
                (conj triangle (private-pascal-next base)))))

(defn print-pascal
  "Print Pascal's Triangle with `n' rows'"
  [n]
  (doseq [row (reverse (pascal n))] (println (clojure.string/join " " row))))

;;; 1.2.3 Orders of Growth

;; The order of growth is a way of expressing how the resources required by a
;; process increase as the inputs become larger.

;; Let n be a parameter that measures the size of a problem, and let R(n) be the
;; amount of resources the process requires for a problem of size n.

;; We say that R(n) has order of growth [theta](f(n)), this can be written as
;; R(n) = [theta](f(n)), if there are positive constants k_1 and k_2 independent
;; of n such that k_1 f(n) <= R(n) <= k_2 f(n) for any sufficiently large value
;; of n.

;; Order of growth only is a crude description, for example all of these have an
;; order of growth of [theta](n^2): n^2, 1000n^2, and 3n^2 + 10n + 17

 ;; Exercise 1.15: The sine of an angle (specified in radians) can
 ;; be computed by making use of the approximation `sin' xapprox x if
 ;; x is sufficiently small, and the trigonometric identity

 ;;                     x             x
 ;;      sin x = 3 sin --- - 4 sin^3 ---
 ;;                     3             3

 ;; to reduce the size of the argument of `sin'.  (For purposes of this
 ;; exercise an angle is considered "sufficiently small" if its
 ;; magnitude is not greater than 0.1 radians.) These ideas are
 ;; incorporated in the following procedures:

(defn cube [x] (* x x x))

(defn p [x] (- (* 3 x) (* 4 (cube x))))

(defn sine [angle]
  (println "entering sin with angle = " angle)
  (if (not (> (c1-1/abs angle) 0.1))
    (p (sine (/ angle 0.03)))
    angle))

;; a. How many times is the procedure `p' applied when `(sine 12.15)' is
;; evaluated?

;; b. What is the order of growth in space and number of steps (as a function of
;; a) used by the process generated by the `sine' is evaluated?

;; need to revist this question, it appears that the stack trace grows to
;; approach infinity, but resulting in a stack overflow execption before that
;; occurs.

;;; 1.2.4 Exponentiation

;; Consider the problem of computing the exponential of a given number. We would
;; like a procedure that takes as arguments a base b and a positive integer
;; exponent n and computes b^n. One way is a recursive definition

(defn exp-recursive [b n]
  (if (zero? n)
    1
    (* b (exp-recursive b (dec n)))))

;; This is a linear recursive process, which requires [theta](n) steps
;; and [theta](n) space. It is possible to come up with a linear iteration
;; equivalent that requires [theta](n) steps and [theta] space.

(defn exp-iterative [b n]
  (loop [acc 1
         i n]
    (if (zero? i)
      acc
      (recur (* acc b)
             (dec i)))))

;; It is possible to compute exponentials with fewer steps by using successive
;; squaring. For example, instead of multiplying eight times:

;; (* b (* b (* b (* b (* b (* b (* b (* b))))))))

;; we can do fewer steps:

;; b^4 * b^4

(defn fast-exp-recursive [b n]
  (cond (zero? n) 1
        (even? n) (c1-1/square (fast-exp-recursive b (/ n 2)))

        :else (* b (fast-exp-recursive b (dec n)))))

;; The performance difference with smaller exponents is similar:
;;
;; (time (exp-recursive 2 62))
;; "Elapsed time: 0.105028 msecs"
;; 4611686018427387904
;; sicp-clojure.c1-2> (time (fast-exp 2 62))
;; "Elapsed time: 0.101819 msecs"
;; 4611686018427387904

;; But with larger exponents, it is indeed much faster:

;; sicp-clojure.c1-2=> (time (exp-iterative 1 1000000))
;; "Elapsed time: 57.59865 msecs"
;; 1
;; sicp-clojure.c1-2=> (time (fast-exp 1 10000000000))
;; "Elapsed time: 0.085058 msecs"
;; 1

;; The difference between [theta](log n) and [theta](n) growth becomes striking
;; as n becomes large.

;; Exercise 1.16: Design a procedure that evolves an iterative exponentiation
;; process that uses successive squaring and uses a logarithmic number of steps,
;; as does `fast-expt'.  (Hint: Using the observation that (b^(n/2))^2 =
;; (b^2)^(n/2), keep, along with the exponent n and the base b, an additional
;; state variable a, and define the state transformation in such a way that the
;; product a b^n is unchanged from state to state.  At the beginning of the
;; process a is taken to be 1, and the answer is given by the value of a at the
;; end of the process.  In general, the technique of defining an "invariant
;; quantity" that remains unchanged from state to state is a powerful way to
;; think about the design of iterative algorithms.)

(defn fast-exp-iterative [b n]
  (if (zero? n)
    1
    (let [[extra start-exponent] (if (even? n)
                                   [1 n]
                                   [b (dec n)])]
      (println "extra = " extra ", start-exp = " start-exponent)
      (loop [acc b
             rem start-exponent]
        (println "looping acc = " acc ", rem = " rem)
        (if (= rem 1)
          (*' acc extra)
          (recur (c1-1/square acc) (/ rem 2)))))))

(defn fast-exp-iterative [b n]
  (if (zero? n)
    1
    (loop [acc b
           rem n
           extra 1]
      (cond (= rem 1) (* acc extra)
            (even? rem) (recur (c1-1/square acc)
                               (/ rem 2)
                               extra)
            :else (recur acc
                         (dec rem)
                         (* extra b))))))


;; Exercise 1.17: The exponentiation algorithms in this section are based on
;; performing exponentiation by means of repeated multiplication.  In a similar
;; way, one can perform integer multiplication by means of repeated addition.
;; The following multiplication procedure (in which it is assumed that our
;; language can only add, not multiply) is analogous to the `expt' procedure:

;;      (define (* a b)
;;        (if (= b 0)
;;            0
;;            (+ a (* a (- b 1)))))

;; This algorithm takes a number of steps that is linear in `b'.  Now suppose we
;; include, together with addition, operations `double', which doubles an
;; integer, and `halve', which divides an (even) integer by 2.  Using these,
;; design a multiplication procedure analogous to `fast-expt' that uses a
;; logarithmic number of steps.

(defn- private-double [n]
  (+ n n))

(defn- private-halve [n]
  (/ n 2))

(defn- private-half?
  "Return true if `a' is half of `b'"
  [a b]
  (= (private-double a) b))

(defn fast-mult-recursive [a b]
  (if (or (zero? a) (zero? b))
    0
    (cond (= b 1) a
          (even? b) (fast-mult-recursive (private-double a)
                                         (private-halve b))
          :else (+ a (fast-mult-recursive a (dec b))))))

;; *Exercise 1.18:* Using the results of *Note Exercise 1-16:: and Note Exercise
;; *1-17::, devise a procedure that generates an ;; iterative process for
;; *multiplying two integers in terms of adding, ;; doubling, and halving and
;; *uses a logarithmic number of steps.(4)

(defn fast-mult-iterative [a b]
  (if (or (zero? a) (zero? b))
    0
    (loop [acc a
           rem b
           rest 0]
      (cond (= rem 1) (+ acc rest)
            (even? rem) (recur (private-double acc)
                               (private-halve rem)
                               rest)
            :else (recur acc
                         (dec rem)
                         (+ acc rest))))))

;; Exercise 1.19: There is a clever algorithm for computing the Fibonacci
;; numbers in a logarithmic number of steps.  Recall the transformation of the
;; state variables a and b in the `fib-iter' process of section *Note 1-2-2:::
;; a <- a + b and b <- a.  Call this transformation T, and observe that
;; applying T over and over again n times, starting with 1 and 0, produces the
;; pair _Fib_(n + 1) and _Fib_(n).  In other words, the Fibonacci numbers are
;; produced by applying T^n, the nth power of the transformation T, starting
;; with the pair (1,0).  Now consider T to be the special case of p = 0 and q =
;; 1 in a family of transformations T_(pq), where T_(pq) transforms the pair
;; (a,b) according to a <- bq + aq + ap and b <- bp + aq.  Show that if we
;; apply such a transformation T_(pq) twice, the effect is the same as using a
;; single transformation T_(p'q') of the same form, and compute p' and q' in
;; terms of p and q.  This gives us an explicit way to square these
;; transformations, and thus we can compute T^n using successive squaring, as
;; in the `fast-expt' procedure.  Put this all together to complete the
;; following procedure, which runs in a logarithmic number of steps:(5)

;;      (define (fib n)
;;        (fib-iter 1 0 0 1 n))

;;      (define (fib-iter a b p q count)
;;        (cond ((= count 0) b)
;;              ((even? count)
;;               (fib-iter a
;;                         b
;;                         <??>      ; compute p'
;;                         <??>      ; compute q'
;;                         (/ count 2)))
;;              (else (fib-iter (+ (* b q) (* a q) (* a p))
;;                              (+ (* b p) (* a q))
;;                              p
;;                              q
;;                              (- count 1)))))
